---
title: Restarted Bayesian Online Change-point Detection for Non-Stationary Markov
  Decision Processes
abstract: We consider the problem of learning in a non-stationary reinforcement learning
  (RL) environment, where the setting can be fully described by a piecewise stationary
  discrete-time Markov decision process (MDP). We introduce a variant of the Restarted
  Bayesian Online Change-Point Detection algorithm (R-BOCPD) that operates on input
  streams originating from the more general multinomial distribution and provides
  near-optimal theoretical guarantees in terms of false-alarm rate and detection delay.
  Based on this, we propose an improved version of the UCRL2 algorithm for MDPs with
  state transition kernel sampled from a multinomial distribution, which we call R-BOCPD-UCRL2.
  We perform a finite-time performance analysis and show that R-BOCPD-UCRL2 enjoys
  a favorable regret bound of $\mathcal{O}\left(D O \sqrt{A T K_T \log\left (\frac{T}{\delta}
  \right)} + \frac{K_T \log \frac{K_T}{\delta}}{\min\limits_\ell \:{KL}(\boldsymbol{\theta}^{(\ell+1)},\boldsymbol{\theta}^{(\ell)})}
  \right)$, where $D$ is the largest MDP diameter from the set of MDPs defining the
  piecewise stationary MDP setting, $O$ is the finite number of states (constant over
  all changes), $A$ is the finite number of actions (constant over all changes), $K_T$
  is the number of change points, and $\boldsymbol{\theta}^{(\ell)}$ is the transition
  kernel during the interval $[c_\ell, c_{\ell+1})$, which we assume to be multinomially
  distributed over the set of states $\mathsf{O}$. Interestingly, the performance
  bound does not directly scale with the variation in MDP state transition distributions
  and rewards, ie. can also model abrupt changes.  In practice, R-BOCPD-UCRL2 outperforms
  the state-of-the-art in a variety of scenarios in synthetic environments. We provide
  a detailed experimental setup along with a code repository (upon publication) that
  can be used to easily reproduce our experiments.
year: '2023'
video: https://youtu.be/rE-DOTgmdPk
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alami23a
month: 0
tex_title: Restarted Bayesian Online Change-point Detection for Non-Stationary Markov
  Decision Processes
firstpage: 715
lastpage: 744
page: 715-744
order: 715
cycles: false
bibtex_author: Alami, Reda and Mahfoud, Mohammed and Moulines, Eric
author:
- given: Reda
  family: Alami
- given: Mohammed
  family: Mahfoud
- given: Eric
  family: Moulines
date: 2023-11-20
address:
container-title: Proceedings of The 2nd Conference on Lifelong Learning Agents
volume: '232'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 11
  - 20
pdf: https://proceedings.mlr.press/v232/alami23a/alami23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
