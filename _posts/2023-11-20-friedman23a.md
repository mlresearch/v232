---
title: Adaptive Meta-Learning via data-dependent PAC-Bayes bounds
abstract: Meta-learning aims to extract common knowledge from similar training tasks
  in order to facilitate efficient and effective learning on future tasks. Several
  recent works have extended PAC-Bayes generalization error bounds to the meta-learning
  setting.  By doing so, prior knowledge can be incorporated in the form of a distribution
  over hypotheses that is expected to lead to low error on new tasks that are similar
  to those that have been previously observed.  In this work, we develop novel bounds
  for the generalization error on test tasks based on recent data-dependent bounds
  and provide a novel algorithm for adapting prior knowledge to downstream tasks in
  a potentially more effective manner.  We demonstrate the effectiveness of our algorithm
  numerically for few-shot image classification tasks with deep neural networks and
  show a significant reduction in generalization error without any additional adaptation
  data.
year: '2023'
video: https://youtu.be/dG1mmlu4Mec
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: friedman23a
month: 0
tex_title: Adaptive Meta-Learning via data-dependent PAC-Bayes bounds
firstpage: 796
lastpage: 810
page: 796-810
order: 796
cycles: false
bibtex_author: Friedman, Lior and Meir, Ron
author:
- given: Lior
  family: Friedman
- given: Ron
  family: Meir
date: 2023-11-20
address:
container-title: Proceedings of The 2nd Conference on Lifelong Learning Agents
volume: '232'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 11
  - 20
pdf: https://proceedings.mlr.press/v232/friedman23a/friedman23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
